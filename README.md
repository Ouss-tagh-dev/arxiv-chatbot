arxiv_chatbot_project/
arxiv_env\Scripts\activate

# arxiv-chatbot

Assistant de recherche avancÃ© pour explorer les articles scientifiques d'arXiv avec interface web, recherche sÃ©mantique, filtres puissants et rÃ©ponses conversationnelles.

---

## Sommaire

1. [PrÃ©sentation](#prÃ©sentation)
2. [PrÃ©requis](#prÃ©requis)
3. [Installation](#installation)
4. [PrÃ©paration des donnÃ©es](#prÃ©paration-des-donnÃ©es)
5. [Lancement de l'application](#lancement-de-lapplication)
6. [Utilisation](#utilisation)
7. [Structure du projet](#structure-du-projet)
8. [Configuration avancÃ©e](#configuration-avancÃ©e)
9. [DÃ©pannage](#dÃ©pannage)
10. [Commandes utiles](#commandes-utiles)
11. [Contact](#contact)

---

## 1. PrÃ©sentation

**arxiv-chatbot** est un assistant de recherche interactif pour explorer, filtrer et analyser les articles scientifiques d'arXiv. Il proposeâ€¯:

- Une interface web moderne (Streamlit)
- Un moteur de recherche sÃ©mantique rapide (FAISS)
- Des filtres avancÃ©s (auteur, annÃ©e, catÃ©gorie, similaritÃ©â€¦)
- Des rÃ©ponses conversationnelles (LLM OpenAI ou modÃ¨les locaux)
- Des outils de nettoyage et de prÃ©paration de donnÃ©es pour de grands jeux de donnÃ©es

---

## 2. PrÃ©requis

- **Python 3.8+** (recommandÃ©â€¯: 3.10 ou 3.11)
- **Git** (pour cloner le projet)
- **Connexion internet** (pour tÃ©lÃ©charger les modÃ¨les et dÃ©pendances)
- **(Optionnel) ClÃ© OpenAI** pour des rÃ©ponses conversationnelles avancÃ©es

---

## 3. Installation

### a. Cloner le projet

```bash
git clone https://github.com/Ouss-tagh-dev/arxiv-chatbot.git
cd arxiv-chatbot
```

### b. CrÃ©er et activer un environnement virtuel

Sous **Windows**â€¯:

```bash
python -m venv arxiv_env
arxiv_env\Scripts\activate
```

Sous **Linux/Mac**â€¯:

```bash
python3 -m venv arxiv_env
source arxiv_env/bin/activate
```

### c. Installer les dÃ©pendances

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## 4. PrÃ©paration des donnÃ©es

### a. Nettoyer les donnÃ©es arXiv

Si vous partez de donnÃ©es brutes (CSV), lancezâ€¯:

```bash
python src/data_cleaning.py --input data/raw/articles.csv --output data/processed/articles_clean.csv --deep-clean --use-spacy --remove-stopwords --lemmatize --sample-size 20000
```

- **--deep-clean**â€¯: nettoyage NLP avancÃ©
- **--use-spacy**â€¯: utilise spaCy pour le traitement linguistique
- **--sample-size**â€¯: (optionnel) pour crÃ©er un sous-Ã©chantillon

### b. GÃ©nÃ©rer les embeddings (vecteurs sÃ©mantiques)

```bash
python generate_index.py --data data/processed/articles_clean.csv --output data/embeddings/ --text_field summary
```

Cela crÃ©e les fichiers d'index FAISS nÃ©cessaires Ã  la recherche rapide.

---

## 5. Lancement de l'application

### a. Interface web (recommandÃ©)

```bash
streamlit run src/chatbot.py -- --web
```

ouâ€¯:

```bash
python -m streamlit run src/chatbot.py -- --web
```

### b. Mode terminal (chat CLI)

```bash
python src/chatbot.py
```

---

## 6. Utilisation

- **Recherche sÃ©mantique**â€¯: tapez une question ou un sujet scientifique
- **Filtres**â€¯: affinez par auteur, annÃ©e, catÃ©gorie, similaritÃ©, etc.
- **Onglet Chat**â€¯: conversation avec lâ€™assistant
- **Onglet RÃ©sultats**â€¯: liste dÃ©taillÃ©e des articles trouvÃ©s
- **Statistiques**â€¯: analyse rapide des rÃ©sultats (catÃ©gories, annÃ©es, auteursâ€¦)

---

## 7. Structure du projet

```
arxiv-chatbot/
â”‚
â”œâ”€â”€ README.md                # Ce guide complet
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ generate_index.py        # GÃ©nÃ©ration des embeddings FAISS
â”œâ”€â”€ get_column.py            # Script utilitaire (extraction de colonnes)
â”œâ”€â”€ test_performance.py      # Script de test de performance
â”œâ”€â”€ Enonce.md                # Sujet ou consignes du projet
â”œâ”€â”€ projet_Master_Python_24_25_250606_111034.pdf # Document projet
â”‚
â”œâ”€â”€ data/                    # DonnÃ©es et artefacts intermÃ©diaires
â”‚   â”œâ”€â”€ raw/                 # DonnÃ©es brutes (CSV, JSON)
â”‚   â”‚   â””â”€â”€ articles.csv
â”‚   â”œâ”€â”€ processed/           # DonnÃ©es nettoyÃ©es (plusieurs CSV, stats JSON)
â”‚   â”‚   â”œâ”€â”€ articles_clean.csv
â”‚   â”‚   â”œâ”€â”€ comprehensive_stats.json
â”‚   â”‚   â”œâ”€â”€ enhanced_cleaning_stats.json
â”‚   â”‚   â”œâ”€â”€ essential_articles_clean.csv
â”‚   â”‚   â””â”€â”€ text_only_articles_clean.csv
â”‚   â”œâ”€â”€ embeddings/          # Index FAISS et mÃ©tadonnÃ©es
â”‚   â”‚   â”œâ”€â”€ faiss_index_all-MiniLM-L6-v2.index
â”‚   â”‚   â””â”€â”€ faiss_metadata_all-MiniLM-L6-v2.pkl
â”‚   â”œâ”€â”€ logs/                # Logs d'import ou de traitement (ex: daily_fetch.log)
â”‚   â”œâ”€â”€ cache/               # (PrÃ©vu) Cache temporaire (actuellement vide)
â”‚   â”œâ”€â”€ cleaned/             # (PrÃ©vu) DonnÃ©es nettoyÃ©es alternatives (vide)
â”‚   â””â”€â”€ interim/             # (PrÃ©vu) Fichiers intermÃ©diaires (vide)
â”‚
â”œâ”€â”€ notebooks/               # Notebooks d'exploration et de traitement
â”‚   â”œâ”€â”€ cleaning_data.ipynb
â”‚   â”œâ”€â”€ extract_data.ipynb
â”‚   â””â”€â”€ old_extract-code.ipynb
â”‚
â”œâ”€â”€ src/                     # Code source Python (modulaire)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chatbot.py           # Moteur de dialogue principal (Streamlit/CLI)
â”‚   â”œâ”€â”€ cleaner.py           # Nettoyage avancÃ© des donnÃ©es
â”‚   â”œâ”€â”€ data_cleaning.py     # Pipeline de nettoyage (script principal)
â”‚   â”œâ”€â”€ data_loader.py       # Chargement et gestion mÃ©moire des donnÃ©es
â”‚   â”œâ”€â”€ embedder.py          # GÃ©nÃ©ration des embeddings sÃ©mantiques
â”‚   â””â”€â”€ search_engine.py     # Recherche sÃ©mantique (FAISS)
â”‚
â”œâ”€â”€ logs/                    # (PrÃ©vu) Logs dâ€™exÃ©cution (vide)
â”œâ”€â”€ stats/                   # (PrÃ©vu) Statistiques additionnelles (vide)
â”œâ”€â”€ models/                  # (PrÃ©vu) ModÃ¨les NLP tÃ©lÃ©chargÃ©s (vide)
â””â”€â”€ .gitignore
```

**Remarquesâ€¯:**

- Les dossiers `cache/`, `cleaned/`, `interim/`, `logs/`, `stats/`, `models/` sont prÃ©vus pour des usages futurs ou pour organiser le flux de donnÃ©es, mÃªme sâ€™ils sont vides par dÃ©faut.
- Le fichier `README.md` est Ã  la racine et sert de guide principal.
- Tous les scripts et modules sont dans `src/` pour une meilleure maintenabilitÃ©.
- Les notebooks sont dÃ©diÃ©s Ã  lâ€™exploration, Ã  la reproductibilitÃ© scientifique et Ã  lâ€™extraction/traitement des donnÃ©es (extraction, nettoyage, analyse exploratoire, etc.).

---

## 8. Configuration avancÃ©e

- **ClÃ© OpenAI**â€¯: pour des rÃ©ponses plus naturelles, ajoutez `--openai-key VOTRE_CLE` lors du lancement
- **Limite mÃ©moire**â€¯: ajustez avec `--memory-limit 4.0` (en Go)
- **ModÃ¨le d'embedding**â€¯: changez avec `--model all-MiniLM-L6-v2` ou un autre modÃ¨le compatible

---

## 9. DÃ©pannage

- **ProblÃ¨me de mÃ©moire**â€¯: le chatbot gÃ¨re automatiquement la mÃ©moire, mais vous pouvez rÃ©duire la taille des donnÃ©es ou la limite mÃ©moire si besoin.
- **Pas de rÃ©sultats**â€¯: vÃ©rifiez que les fichiers dâ€™index sont bien gÃ©nÃ©rÃ©s et que les donnÃ©es sont propres.
- **Erreur OpenAI**â€¯: assurez-vous dâ€™avoir une clÃ© valide et une connexion internet.
- **DÃ©pendances manquantes**â€¯: relancez `pip install -r requirements.txt`.

---

## 10. Commandes utiles

```bash
# Nettoyer les donnÃ©es
python src/data_cleaning.py --input data/raw/articles.csv --output data/processed/articles_clean.csv --deep-clean --use-spacy

# GÃ©nÃ©rer les embeddings
python generate_index.py --data data/processed/articles_clean.csv --output data/embeddings/ --text_field summary

# Lancer lâ€™interface web
streamlit run src/chatbot.py -- --web

# Lancer le chat en terminal
python src/chatbot.py
```

---

## ğŸ‘¥ Contributeurs

| Membre            | GitHub                                               |
| ----------------- | -----------------------------------------------------|
| Oussama TAGHLAOUI | [ouss-tagh-dev](https://github.com/ouss-tagh-dev)    |
| Abd'allah Ismaili | [AbdallahIsmaili](https://github.com/AbdallahIsmaili)|
| Sanaa AZZA        | [sanaaazza](https://github.com/sanaaazza)            |